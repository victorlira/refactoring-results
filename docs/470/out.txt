source(java.util.ArrayList, <init>, -1, ArrayList.<java.util.ArrayList: java.lang.Object[] elementData> = null, [at com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat.getSplits(AvroKeyCombineFileInputFormat.java:44)]) => sink(java.util.ArrayList, <init>, -1, ArrayList.<java.util.ArrayList: java.lang.Object[] elementData> = null, [at com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat.getSplits(AvroKeyCombineFileInputFormat.java:44)])

source(java.util.ArrayList, <init>, -1, ArrayList.<java.util.ArrayList: int size> = null, [at com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat.getSplits(AvroKeyCombineFileInputFormat.java:44)]) => sink(java.util.ArrayList, <init>, -1, ArrayList.<java.util.ArrayList: int size> = null, [at com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat.getSplits(AvroKeyCombineFileInputFormat.java:44)])

source(com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat, getSplits, 44, $stack14 = new java.util.ArrayList, [at com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat.getSplits(AvroKeyCombineFileInputFormat.java:44)]) => sink(com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat, getSplits, 44, $stack14 = new java.util.ArrayList, [at com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat.getSplits(AvroKeyCombineFileInputFormat.java:44)])

source(com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat, getSplits, 44, splits = $stack14, [at com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat.getSplits(AvroKeyCombineFileInputFormat.java:44)]) => sink(com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat, getSplits, 44, splits = $stack14, [at com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat.getSplits(AvroKeyCombineFileInputFormat.java:44)])

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter2: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir),96,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir), 96)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,f = l6[l8],102,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, f = l6[l8], 102)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack23 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(),98,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack23 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(), 98)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack24 = staticinvoke <java.util.Collections: java.util.List singletonList(java.lang.Object)>($stack23),98,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack24 = staticinvoke <java.util.Collections: java.util.List singletonList(java.lang.Object)>($stack23), 98)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,dirs := @parameter1: java.util.List,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l4 = interfaceinvoke dirs.<java.util.List: java.util.Iterator iterator()>(),95,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l4 = interfaceinvoke dirs.<java.util.List: java.util.Iterator iterator()>(), 95)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter2: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir),96,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir), 96)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,f = l6[l8],102,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, f = l6[l8], 102)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter2: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir),96,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir), 96)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,f = l6[l8],102,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, f = l6[l8], 102)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack15 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: boolean isDir()>(),97,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack15 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: boolean isDir()>(), 97)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack28 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path)>(input),68,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack28 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path)>(input), 68)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs),74,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter2: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir),96,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir), 96)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,f = l6[l8],102,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, f = l6[l8], 102)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack23 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(),98,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack23 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(), 98)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack24 = staticinvoke <java.util.Collections: java.util.List singletonList(java.lang.Object)>($stack23),98,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack24 = staticinvoke <java.util.Collections: java.util.List singletonList(java.lang.Object)>($stack23), 98)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,dirs := @parameter1: java.util.List,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l4 = interfaceinvoke dirs.<java.util.List: java.util.Iterator iterator()>(),95,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l4 = interfaceinvoke dirs.<java.util.List: java.util.Iterator iterator()>(), 95)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack12 = interfaceinvoke l4.<java.util.Iterator: java.lang.Object next()>(),103,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack12 = interfaceinvoke l4.<java.util.Iterator: java.lang.Object next()>(), 103)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter2: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir),96,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir), 96)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter2: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir),96,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir), 96)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,f = l6[l8],102,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, f = l6[l8], 102)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack16 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(),99,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack16 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(), 99)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack17 = virtualinvoke $stack16.<org.apache.hadoop.fs.Path: java.lang.String getName()>(),99,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack17 = virtualinvoke $stack16.<org.apache.hadoop.fs.Path: java.lang.String getName()>(), 99)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter2: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir),96,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir), 96)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,f = l6[l8],102,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, f = l6[l8], 102)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack23 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(),98,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack23 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(), 98)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack28 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path)>(input),68,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack28 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path)>(input), 68)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,count = virtualinvoke $stack28.<org.apache.hadoop.fs.ContentSummary: long getFileCount()>(),68,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, count = virtualinvoke $stack28.<org.apache.hadoop.fs.ContentSummary: long getFileCount()>(), 68)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fileCount = fileCount + count,71,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack31 = fileCount + count, 70)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack31 = fileCount + count,70,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack31 = fileCount + count, 70)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack32 = $stack31 cmp 5000L,70,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack32 = $stack31 cmp 5000L, 70)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs),46,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack14 = new java.util.ArrayList,44,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke $stack14.<java.util.ArrayList: void <init>()>(), 44)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,splits = $stack14,44,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, splits = $stack14, 44)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,splits := @parameter2: java.util.List,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,interfaceinvoke splits.<java.util.List: boolean addAll(java.util.Collection)>($stack40),78,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, interfaceinvoke splits.<java.util.List: boolean addAll(java.util.Collection)>($stack40), 78)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack14 = new java.util.ArrayList,44,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke $stack14.<java.util.ArrayList: void <init>()>(), 44)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,splits = $stack14,44,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, splits = $stack14, 44)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs),46,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter2: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir),96,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, l6 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path)>(dir), 96)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,f = l6[l8],102,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, f = l6[l8], 102)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack21 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(),100,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 74) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack21 = virtualinvoke f.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>(), 100)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack28 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path)>(input),68,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack28 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path)>(input), 68)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,count = virtualinvoke $stack28.<org.apache.hadoop.fs.ContentSummary: long getFileCount()>(),68,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, count = virtualinvoke $stack28.<org.apache.hadoop.fs.ContentSummary: long getFileCount()>(), 68)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fileCount = fileCount + count,71,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack31 = fileCount + count, 70)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs),86,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllAvro(java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(files, subdirs, fs), 86)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack14 = new java.util.ArrayList,44,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke $stack14.<java.util.ArrayList: void <init>()>(), 44)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,splits = $stack14,44,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, splits = $stack14, 44)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,splits := @parameter2: java.util.List,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,interfaceinvoke splits.<java.util.List: boolean addAll(java.util.Collection)>($stack25),90,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, interfaceinvoke splits.<java.util.List: boolean addAll(java.util.Collection)>($stack25), 90)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fs := @parameter3: org.apache.hadoop.fs.FileSystem,-1,SimpleNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack28 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path)>(input),68,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack28 = virtualinvoke fs.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path)>(input), 68)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,count = virtualinvoke $stack28.<org.apache.hadoop.fs.ContentSummary: long getFileCount()>(),68,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, count = virtualinvoke $stack28.<org.apache.hadoop.fs.ContentSummary: long getFileCount()>(), 68)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,fileCount = fileCount + count,71,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack31 = fileCount + count, 70)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>,$stack17 = fileCount cmp 0L,84,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46) => (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>, $stack17 = fileCount cmp 0L, 84)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack14 = new java.util.ArrayList,44,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke $stack14.<java.util.ArrayList: void <init>()>(), 44)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,splits = $stack14,44,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, splits = $stack14, 44)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs),46,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)))

List(Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,$stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, $stack8 = virtualinvoke arg0.<org.apache.hadoop.mapreduce.JobContext: org.apache.hadoop.conf.Configuration getConfiguration()>(), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8),39,SourceNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, fs = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>($stack8), 39)) => Node(<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>,specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs),46,SinkNode, path: (<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>, specialinvoke this.<com.linkedin.camus.sweeper.mapreduce.AvroKeyCombineFileInputFormat: void addAllSplits(org.apache.hadoop.mapreduce.JobContext,java.util.List,java.util.List,org.apache.hadoop.fs.FileSystem)>(arg0, $stack16, splits, fs), 46)))

